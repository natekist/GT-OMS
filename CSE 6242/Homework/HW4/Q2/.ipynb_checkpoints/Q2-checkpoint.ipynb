{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import csv\n",
    "import numpy as np  # http://www.numpy.org\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from math import log, floor, ceil\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Utility class's methods. You can also add additional methods as required but don't change existing methods' arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Utility(object):\n",
    "    \n",
    "    # This method computes entropy for information gain\n",
    "    def entropy(self, class_y):\n",
    "        # Input:            \n",
    "        #   class_y         : list of class labels (0's and 1's)\n",
    "\n",
    "        # TODO: Compute the entropy for a list of classes\n",
    "        #\n",
    "        # Example:\n",
    "        #    entropy([0,0,0,1,1,1,1,1,1]) = 0.918 (rounded to three decimal places)\n",
    "\n",
    "        entropy = 0\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        ones = class_y.count(1)\n",
    "        zeroes = class_y.count(0)\n",
    "        if ones == 0 or zeroes == 0:\n",
    "            return 0\n",
    "\n",
    "        p_ones = ones / (ones + zeroes)\n",
    "        p_zeroes = zeroes / (ones + zeroes)\n",
    "        \n",
    "        if p_zeroes == 0 or p_ones == 0:\n",
    "            return 0\n",
    "        e = - (p_ones * log(p_ones, 2)) - (p_zeroes * log(p_zeroes, 2))\n",
    "        \n",
    "        entropy += e\n",
    "        #############################################\n",
    "        return entropy\n",
    "\n",
    "    def partition_classes(self, X, y, split_attribute, split_val):\n",
    "        # Inputs:\n",
    "        #   X               : data containing all attributes\n",
    "        #   y               : labels\n",
    "        #   split_attribute : column index of the attribute to split on\n",
    "        #   split_val       : a numerical value to divide the split_attribute\n",
    "\n",
    " \n",
    "\n",
    "        # TODO: Partition the data(X) and labels(y) based on the split value - BINARY SPLIT.\n",
    "        # \n",
    "        # Split_val should be a numerical value\n",
    "        # For example, your split_val could be the mean of the values of split_attribute\n",
    "        #\n",
    "        # You can perform the partition in the following way\n",
    "        # Numeric Split Attribute:\n",
    "        #   Split the data X into two lists(X_left and X_right) where the first list has all\n",
    "        #   the rows where the split attribute is less than or equal to the split value, and the \n",
    "        #   second list has all the rows where the split attribute is greater than the split \n",
    "        #   value. Also create two lists(y_left and y_right) with the corresponding y labels.\n",
    "\n",
    " \n",
    "\n",
    "        '''\n",
    "        Example:\n",
    "\n",
    " \n",
    "\n",
    "        X = [[3, 10],                 y = [1,\n",
    "             [1, 22],                      1,\n",
    "             [2, 28],                      0,\n",
    "             [5, 32],                      0,\n",
    "             [4, 32]]                      1]\n",
    "\n",
    " \n",
    "\n",
    "        Here, columns 0 and 1 represent numeric attributes.\n",
    "\n",
    " \n",
    "\n",
    "        Consider the case where we call the function with split_attribute = 0 and split_val = 3 (mean of column 0)\n",
    "        Then we divide X into two lists - X_left, where column 0 is <= 3  and X_right, where column 0 is > 3.\n",
    "\n",
    " \n",
    "\n",
    "        X_left = [[3, 10],                 y_left = [1,\n",
    "                  [1, 22],                           1,\n",
    "                  [2, 28]]                           0]\n",
    "\n",
    " \n",
    "\n",
    "        X_right = [[5, 32],                y_right = [0,\n",
    "                   [4, 32]]                           1]\n",
    "\n",
    " \n",
    "\n",
    "        ''' \n",
    "\n",
    "        X_left = []\n",
    "        X_right = []\n",
    "\n",
    "        y_left = []\n",
    "        y_right = []\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        for i in range(len(X)):\n",
    "            if X[i][split_attribute] > split_val:\n",
    "                X_right.append(X[i])\n",
    "                y_right.append(y[i])\n",
    "            else:\n",
    "                X_left.append(X[i])\n",
    "                y_left.append(y[i])\n",
    "        #############################################\n",
    "        return (X_left, X_right, y_left, y_right)\n",
    "\n",
    "\n",
    "    def information_gain(self, previous_y, current_y):\n",
    "        # Inputs:\n",
    "        #   previous_y: the distribution of original labels (0's and 1's)\n",
    "        #   current_y:  the distribution of labels after splitting based on a particular\n",
    "        #               split attribute and split value\n",
    "\n",
    "        # TODO: Compute and return the information gain from partitioning the previous_y labels\n",
    "        # into the current_y labels.\n",
    "        # You will need to use the entropy function above to compute information gain\n",
    "        # Reference: http://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15381-s06/www/DTs.pdf\n",
    "\n",
    "        \"\"\"\n",
    "        Example:\n",
    "\n",
    "        previous_y = [0,0,0,1,1,1]\n",
    "        current_y = [[0,0], [1,1,1,0]]\n",
    "\n",
    "        info_gain = 0.45915\n",
    "        \"\"\"\n",
    "        info_gain = 0\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        info_gain = Utility().entropy(previous_y) - (len(current_y[0]) / len(previous_y)) * Utility().entropy(current_y[0]) - (len(current_y[1]) / len(previous_y)) * Utility().entropy(current_y[1])\n",
    "\n",
    "        #############################################\n",
    "        return info_gain\n",
    "\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        # Inputs:\n",
    "        #   X       : Data containing all attributes\n",
    "        #   y       : labels\n",
    "        #   TODO    : For each node find the best split criteria and return the split attribute, \n",
    "        #             spliting value along with  X_left, X_right, y_left, y_right (using partition_classes) \n",
    "        #             in the dictionary format {'split_attribute':split_attribute, 'split_val':split_val, \n",
    "        #             'X_left':X_left, 'X_right':X_right, 'y_left':y_left, 'y_right':y_right, 'info_gain':info_gain}\n",
    "        '''\n",
    "\n",
    "        Example: \n",
    "\n",
    "        X = [[3, 10],                 y = [1, \n",
    "             [1, 22],                      1, \n",
    "             [2, 28],                      0, \n",
    "             [5, 32],                      0, \n",
    "             [4, 32]]                      1] \n",
    "\n",
    "        Starting entropy: 0.971 \n",
    "\n",
    "        Calculate information gain at splits: (In this example, we are testing all values in an \n",
    "        attribute as a potential split value, but you can experiment with different values in your implementation) \n",
    "\n",
    "        feature 0:  -->    split_val = 1  -->  info_gain = 0.17 \n",
    "                           split_val = 2  -->  info_gain = 0.01997 \n",
    "                           split_val = 3  -->  info_gain = 0.01997 \n",
    "                           split_val = 4  -->  info_gain = 0.32 \n",
    "                           split_val = 5  -->  info_gain = 0 \n",
    "                           \n",
    "                           best info_gain = 0.32, best split_val = 4 \n",
    "\n",
    "\n",
    "        feature 1:  -->    split_val = 10  -->  info_gain = 0.17 \n",
    "                           split_val = 22  -->  info_gain = 0.41997 \n",
    "                           split_val = 28  -->  info_gain = 0.01997 \n",
    "                           split_val = 32  -->  info_gain = 0 \n",
    "\n",
    "                           best info_gain = 0.4199, best split_val = 22 \n",
    "\n",
    " \n",
    "       best_split_feature: 1  \n",
    "       best_split_val: 22  \n",
    "\n",
    "       'X_left': [[3, 10], [1, 22]]  \n",
    "       'X_right': [[2, 28],[5, 32], [4, 32]]  \n",
    "\n",
    "       'y_left': [1, 1]  \n",
    "       'y_right': [0, 0, 1] \n",
    "        '''\n",
    "        \n",
    "        split_attribute = 0\n",
    "        split_val = 0\n",
    "        X_left, X_right, y_left, y_right = [], [], [], []\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        \n",
    "        max_iGain = 0\n",
    "        #Loop through all features\n",
    "        for i in range(len(X[0])):\n",
    "            current_col = [row[i] for row in X]\n",
    "            steps = set(current_col)\n",
    "            for step in steps:\n",
    "                #Iterate through defined test vals and determine the information gain\n",
    "                X_left, X_right, y_left, y_right = Utility().partition_classes(X, y, i, step)\n",
    "                new_y = [y_left, y_right]\n",
    "                iGain = Utility().information_gain(y, new_y)\n",
    "                if iGain > max_iGain:\n",
    "                    best_iGain = iGain\n",
    "                    split_val = step\n",
    "                    split_attribute = i\n",
    "                    r_X_left = X_left\n",
    "                    r_X_right = X_right\n",
    "                    r_y_left = y_left\n",
    "                    r_y_right = y_right\n",
    "        ans =  {'split_attribute':split_attribute, 'split_val':split_val, 'X_left':r_X_left, 'X_right':r_X_right, 'y_left':r_y_left, 'y_right':r_y_right, 'info_gain':best_iGain}\n",
    "        return ans\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'split_attribute': 1,\n",
       " 'split_val': 22,\n",
       " 'X_left': [[3, 10], [1, 22]],\n",
       " 'X_right': [[2, 28], [5, 32], [4, 32]],\n",
       " 'y_left': [1, 1],\n",
       " 'y_right': [0, 0, 1],\n",
       " 'info_gain': 0.4199730940219749}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Utility().best_split([[3, 10],[1, 22],[2, 28],[5, 32], [4, 32]],[1, 1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classes 'DecisionTree' and 'RandomForest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please modify the 'DecisionTree' and 'RandomForest' classes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, max_depth):\n",
    "        # Initializing the tree as an empty dictionary or list, as preferred\n",
    "        self.tree = {}\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    \t\n",
    "    def learn(self, X, y, par_node = {}, depth=0):\n",
    "        # TODO: Train the decision tree (self.tree) using the the sample X and labels y\n",
    "        # You will have to make use of the functions in Utility class to train the tree\n",
    "        \n",
    "        # par_node is a parameter that is useful to pass additional information to call \n",
    "        # the learn method recursively. Its not mandatory to use this parameter\n",
    "\n",
    "        # Use the function best_split in Utility class to get the best split and \n",
    "        # data corresponding to left and right child nodes\n",
    "        \n",
    "        # One possible way of implementing the tree:\n",
    "        #    Each node in self.tree could be in the form of a dictionary:\n",
    "        #       https://docs.python.org/2/library/stdtypes.html#mapping-types-dict\n",
    "        #    For example, a non-leaf node with two children can have a 'left' key and  a \n",
    "        #    'right' key. You can add more keys which might help in classification\n",
    "        #    (eg. split attribute and split value)\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        \n",
    "        # Handle edge cases to set as leaves\n",
    "        \n",
    "        if len(X) == 0 or len(y) == 0:\n",
    "            self.tree['node_description'] = 'leaf'\n",
    "            self.tree['result'] = 0\n",
    "            return\n",
    "        \n",
    "        #Test to see if all the predictions are are the saem. If so set as leaf.\n",
    "        if len(set(y)) == 1:\n",
    "            self.tree['node_description'] = 'leaf'\n",
    "            self.tree['result'] = y[0]\n",
    "            return\n",
    "        \n",
    "        #Initialize empty dictionary to collect information about the current predictions\n",
    "        temp_dict = {}\n",
    "        \n",
    "        #Loop through the labels\n",
    "        for label in y:\n",
    "            if label in temp_dict.keys():\n",
    "                temp_dict[label] += 1\n",
    "            else:\n",
    "                temp_dict[label] = 1\n",
    "        \n",
    "        y_max_val = 0\n",
    "        y_max_count = 0\n",
    "        \n",
    "        #Determine if 0 or 1 has a greater number of counts\n",
    "        for i, j in temp_dict.items():\n",
    "            if j > y_max_count:\n",
    "                y_max_val = i\n",
    "                y_max_count = j\n",
    "        print(y_max_val, y_max_count, depth)\n",
    "        #Stop if the depth is at the max depth and designate as a leaf\n",
    "        if depth == self.max_depth:\n",
    "            self.tree['node_description'] = 'leaf'\n",
    "            self.tree['result'] = y_max_val\n",
    "            return\n",
    "                \n",
    "        split = Utility().best_split(X, y)\n",
    "\n",
    "        self.tree['node_description'] = \"parent\"\n",
    "        self.tree['result'] = \"null\"\n",
    "\n",
    "        self.tree['split_attr'] = split['split_attribute']\n",
    "        self.tree['split_val'] = split['split_val']\n",
    "        \n",
    "        #Implement recursion by growing the left and right sides of the tree\n",
    "        \n",
    "        self.tree['left'] = DecisionTree(1000)\n",
    "        self.tree['left'].learn(split['X_left'], split['y_left'], self, depth+1)\n",
    "        \n",
    "        self.tree['right'] = DecisionTree(1000)\n",
    "        self.tree['right'].learn(split['X_right'], split['y_right'], self, depth+1) \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #############################################\n",
    "\n",
    "\n",
    "    def classify(self, record):\n",
    "        # TODO: classify the record using self.tree and return the predicted label\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        if self.tree['node_description']=='leaf':\n",
    "            return self.tree['result']\n",
    "        \n",
    "        else:\n",
    "            attribute = record[self.tree['split_attr']]\n",
    "            value = self.tree['split_val']\n",
    "            if attribute <= value:\n",
    "                return self.tree['left'].classify(record)\n",
    "            else:\n",
    "                return self.tree['right'].classify(record)\n",
    "        pass\n",
    "        #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This starter code does not run. You will have to add your changes and\n",
    "# turn in code that runs properly.\n",
    "\n",
    "\"\"\"\n",
    "Here, \n",
    "1. X is assumed to be a matrix with n rows and d columns where n is the\n",
    "number of total records and d is the number of features of each record. \n",
    "2. y is assumed to be a vector of labels of length n.\n",
    "3. XX is similar to X, except that XX also contains the data label for each\n",
    "record.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "This skeleton is provided to help you implement the assignment.You must \n",
    "implement the existing functions as necessary. You may add new functions\n",
    "as long as they are called from within the given classes. \n",
    "\n",
    "VERY IMPORTANT!\n",
    "Do NOT change the signature of the given functions.\n",
    "Do NOT change any part of the main function APART from the forest_size parameter.  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class RandomForest(object):\n",
    "    num_trees = 1\n",
    "    decision_trees = []\n",
    "\n",
    "    # the bootstrapping datasets for trees\n",
    "    # bootstraps_datasets is a list of lists, where each list in bootstraps_datasets is a bootstrapped dataset.\n",
    "    bootstraps_datasets = []\n",
    "\n",
    "    # the true class labels, corresponding to records in the bootstrapping datasets\n",
    "    # bootstraps_labels is a list of lists, where the 'i'th list contains the labels corresponding to records in\n",
    "    # the 'i'th bootstrapped dataset.\n",
    "    bootstraps_labels = []\n",
    "\n",
    "    def __init__(self, num_trees):\n",
    "        # Initialization done here\n",
    "        self.num_trees = num_trees\n",
    "        self.decision_trees = [DecisionTree(max_depth=10) for i in range(num_trees)]\n",
    "        self.bootstraps_datasets = []\n",
    "        self.bootstraps_labels = []\n",
    "        \n",
    "    def _bootstrapping(self, XX, n):\n",
    "        # Reference: https://en.wikipedia.org/wiki/Bootstrapping_(statistics)\n",
    "        #\n",
    "        # TODO: Create a sample dataset of size n by sampling with replacement\n",
    "        #       from the original dataset XX.\n",
    "        # Note that you would also need to record the corresponding class labels\n",
    "        # for the sampled records for training purposes.\n",
    "\n",
    "        sample = [] # sampled dataset\n",
    "        labels = []  # class labels for the sampled records\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        \n",
    "        #Generate indexes of randomly chosen rows\n",
    "        idx = np.random.choice(len(XX), n)    \n",
    "        \n",
    "        #Collect rows that were chosen at reandom\n",
    "        raw_sample = [XX[i] for i in idx]\n",
    "        \n",
    "        #Append data and labels to respective lists\n",
    "        for s in raw_sample:\n",
    "            sample.append(s[:-1])\n",
    "            labels.append(s[-1])\n",
    "        #############################################\n",
    "        return (sample, labels)\n",
    "\n",
    "    def bootstrapping(self, XX):\n",
    "        # Initializing the bootstap datasets for each tree\n",
    "        for i in range(self.num_trees):\n",
    "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
    "            self.bootstraps_datasets.append(data_sample)\n",
    "            self.bootstraps_labels.append(data_label)\n",
    "\n",
    "    def fitting(self):\n",
    "        # TODO: Train `num_trees` decision trees using the bootstraps datasets\n",
    "        # and labels by calling the learn function from your DecisionTree class.\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        #Loop through the number of trees defined by num_trees\n",
    "        for i in range(self.num_trees):\n",
    "            # For each tree add the lean\n",
    "            self.decision_trees[i].learn(self.bootstraps_datasets[i], self.bootstraps_labels[i])\n",
    "        \n",
    "        pass\n",
    "        #############################################\n",
    "\n",
    "    def voting(self, X):\n",
    "        y = []\n",
    "\n",
    "        for record in X:\n",
    "            # Following steps have been performed here:\n",
    "            #   1. Find the set of trees that consider the record as an\n",
    "            #      out-of-bag sample.\n",
    "            #   2. Predict the label using each of the above found trees.\n",
    "            #   3. Use majority vote to find the final label for this recod.\n",
    "            votes = []\n",
    "            \n",
    "            for i in range(len(self.bootstraps_datasets)):\n",
    "                dataset = self.bootstraps_datasets[i]\n",
    "                \n",
    "                if record not in dataset:\n",
    "                    OOB_tree = self.decision_trees[i]\n",
    "                    effective_vote = OOB_tree.classify(record)\n",
    "                    votes.append(effective_vote)\n",
    "\n",
    "            counts = np.bincount(votes)\n",
    "\n",
    "            if len(counts) == 0:\n",
    "                # TODO: Special case\n",
    "                #  Handle the case where the record is not an out-of-bag sample\n",
    "                #  for any of the trees.\n",
    "                # NOTE - you can add few lines of codes above (but inside voting) to make this work\n",
    "                ### Implement your code here\n",
    "                #############################################\n",
    "                for tree in self.decision_trees:\n",
    "                    votes.append(tree.classify(record))\n",
    "                counts = np.bincount(votes)\n",
    "                y = np.append(y, np.argmax(counts))\n",
    "                pass\n",
    "                #############################################\n",
    "            else:\n",
    "                y = np.append(y, np.argmax(counts))\n",
    "                \n",
    "        return y\n",
    "\n",
    "    def user(self):\n",
    "        \"\"\"\n",
    "        :return: string\n",
    "        your GTUsername, NOT your 9-Digit GTId  \n",
    "        \"\"\"\n",
    "        ### Implement your code here\n",
    "        #############################################\n",
    "        return 'nkistler3'\n",
    "        #############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# TODO: Determine the forest size according to your implementation. \n",
    "# This function will be used by the autograder to set your forest size during testing\n",
    "# VERY IMPORTANT: Minimum forest_size should be 10\n",
    "def get_forest_size():\n",
    "    forest_size = 10\n",
    "    return forest_size\n",
    "\n",
    "# TODO: Determine random seed to set for reproducibility\n",
    "# This function will be used by the autograder to set the random seed to obtain the same results you achieve locally\n",
    "def get_random_seed():\n",
    "    random_seed = 0\n",
    "    return random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do not modify the below cell\n",
    "The cell below is provided to test that your random forest classifier can be successfully built and run. Similar steps will be used to build and run your code in Gradescope. Any additional testing of functions can be done in the cells below the `%run helpers/notebook2script submission` cell, as these will not be parsed by the autograder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    np.random.seed(get_random_seed())\n",
    "    # start time \n",
    "    start = datetime.now()\n",
    "    X = list()\n",
    "    y = list()\n",
    "    XX = list()  # Contains data features and data labels\n",
    "    numerical_cols = set([i for i in range(0, 9)])  # indices of numeric attributes (columns)\n",
    "\n",
    "    # Loading data set\n",
    "    print(\"reading the data\")\n",
    "    with open(\"pima-indians-diabetes.csv\") as f:\n",
    "        next(f, None)\n",
    "        for line in csv.reader(f, delimiter=\",\"):\n",
    "            xline = []\n",
    "            for i in range(len(line)):\n",
    "                if i in numerical_cols:\n",
    "                    xline.append(ast.literal_eval(line[i]))\n",
    "                else:\n",
    "                    xline.append(line[i])\n",
    "\n",
    "            X.append(xline[:-1])\n",
    "            y.append(xline[-1])\n",
    "            XX.append(xline[:])\n",
    "\n",
    "    # Initializing a random forest.\n",
    "    randomForest = RandomForest(get_forest_size())\n",
    "\n",
    "    # printing the name\n",
    "    print(\"__Name: \" + randomForest.user()+\"__\")\n",
    "\n",
    "    # Creating the bootstrapping datasets\n",
    "    print(\"creating the bootstrap datasets\")\n",
    "    randomForest.bootstrapping(XX)\n",
    "\n",
    "    # Building trees in the forest\n",
    "    print(\"fitting the forest\")\n",
    "    randomForest.fitting()\n",
    "\n",
    "    # Calculating an unbiased error estimation of the random forest\n",
    "    # based on out-of-bag (OOB) error estimate.\n",
    "    y_predicted = randomForest.voting(X)\n",
    "\n",
    "    # Comparing predicted and true labels\n",
    "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = float(results.count(True)) / float(len(results))\n",
    "\n",
    "    print(\"accuracy: %.4f\" % accuracy)\n",
    "    print(\"OOB estimate: %.4f\" % (1 - accuracy))\n",
    "\n",
    "    # end time\n",
    "    print(\"Execution time: \" + str(datetime.now() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the data\n",
      "__Name: nkistler3__\n",
      "creating the bootstrap datasets\n",
      "fitting the forest\n",
      "0 478 0\n",
      "0 476 1\n",
      "0 476 2\n",
      "0 474 3\n",
      "0 472 4\n",
      "0 471 5\n",
      "0 468 6\n",
      "0 467 7\n",
      "0 465 8\n",
      "0 463 9\n",
      "0 462 10\n",
      "0 460 11\n",
      "0 458 12\n",
      "0 457 13\n",
      "0 453 14\n",
      "0 453 15\n",
      "0 452 16\n",
      "0 449 17\n",
      "0 447 18\n",
      "0 443 19\n",
      "0 440 20\n",
      "0 438 21\n",
      "0 436 22\n",
      "0 431 23\n",
      "0 430 24\n",
      "0 425 25\n",
      "0 422 26\n",
      "0 420 27\n",
      "0 416 28\n",
      "0 410 29\n",
      "0 403 30\n",
      "0 398 31\n",
      "0 388 32\n",
      "0 323 33\n",
      "0 314 34\n",
      "0 299 35\n",
      "0 280 36\n",
      "0 248 37\n",
      "0 234 38\n",
      "0 209 39\n",
      "0 174 40\n",
      "0 143 41\n",
      "0 116 42\n",
      "0 64 43\n",
      "0 48 44\n",
      "0 3 45\n",
      "1 3 46\n",
      "0 16 44\n",
      "0 11 45\n",
      "0 10 46\n",
      "0 8 47\n",
      "0 5 48\n",
      "0 2 49\n",
      "0 5 45\n",
      "0 3 46\n",
      "0 52 43\n",
      "0 38 44\n",
      "0 29 45\n",
      "0 23 46\n",
      "0 23 47\n",
      "0 18 48\n",
      "0 8 49\n",
      "0 6 50\n",
      "0 4 51\n",
      "0 2 50\n",
      "0 1 51\n",
      "0 10 49\n",
      "0 5 50\n",
      "0 2 51\n",
      "0 14 44\n",
      "0 12 45\n",
      "0 8 46\n",
      "0 5 47\n",
      "1 3 48\n",
      "1 3 49\n",
      "1 8 46\n",
      "0 4 47\n",
      "0 4 48\n",
      "0 27 42\n",
      "0 5 43\n",
      "0 4 44\n",
      "0 1 45\n",
      "0 22 43\n",
      "0 21 44\n",
      "0 12 45\n",
      "0 10 46\n",
      "0 3 47\n",
      "0 1 48\n",
      "1 11 45\n",
      "1 11 46\n",
      "1 11 47\n",
      "1 11 48\n",
      "1 9 49\n",
      "1 4 50\n",
      "0 31 41\n",
      "0 24 42\n",
      "0 19 43\n",
      "0 17 44\n",
      "0 13 45\n",
      "0 13 46\n",
      "0 2 47\n",
      "1 1 48\n",
      "0 11 47\n",
      "0 2 48\n",
      "0 7 42\n",
      "0 5 43\n",
      "1 4 44\n",
      "1 3 45\n",
      "1 3 46\n",
      "1 2 47\n",
      "0 35 40\n",
      "0 9 41\n",
      "0 6 42\n",
      "0 26 41\n",
      "0 19 42\n",
      "0 14 43\n",
      "0 7 44\n",
      "0 2 45\n",
      "1 2 46\n",
      "0 1 47\n",
      "0 5 45\n",
      "0 2 46\n",
      "0 7 44\n",
      "1 5 45\n",
      "1 5 46\n",
      "0 5 43\n",
      "0 1 44\n",
      "0 4 44\n",
      "0 25 39\n",
      "0 12 40\n",
      "0 11 41\n",
      "0 3 42\n",
      "0 3 43\n",
      "0 8 42\n",
      "0 1 43\n",
      "0 7 43\n",
      "0 3 44\n",
      "0 13 40\n",
      "0 6 41\n",
      "0 3 42\n",
      "0 2 43\n",
      "0 7 41\n",
      "0 5 42\n",
      "0 14 38\n",
      "0 8 39\n",
      "0 7 40\n",
      "0 6 41\n",
      "0 2 42\n",
      "0 1 43\n",
      "0 6 39\n",
      "0 1 40\n",
      "0 5 40\n",
      "0 4 41\n",
      "1 3 42\n",
      "0 2 43\n",
      "1 1 41\n",
      "0 32 37\n",
      "0 15 38\n",
      "0 14 39\n",
      "0 9 40\n",
      "0 6 41\n",
      "0 4 42\n",
      "0 3 43\n",
      "0 5 40\n",
      "0 4 41\n",
      "1 2 39\n",
      "0 17 38\n",
      "0 8 39\n",
      "0 6 40\n",
      "0 4 41\n",
      "0 3 42\n",
      "0 2 40\n",
      "0 9 39\n",
      "0 8 40\n",
      "0 6 41\n",
      "0 3 42\n",
      "0 2 43\n",
      "0 2 41\n",
      "1 1 42\n",
      "0 19 36\n",
      "0 10 37\n",
      "0 7 38\n",
      "1 2 39\n",
      "1 4 38\n",
      "0 3 39\n",
      "0 2 40\n",
      "1 2 41\n",
      "0 1 42\n",
      "0 9 37\n",
      "0 3 38\n",
      "0 2 39\n",
      "0 6 38\n",
      "0 4 39\n",
      "0 4 40\n",
      "1 2 39\n",
      "0 2 40\n",
      "0 15 35\n",
      "0 14 36\n",
      "0 6 37\n",
      "1 9 37\n",
      "1 9 38\n",
      "1 8 39\n",
      "1 4 40\n",
      "1 4 41\n",
      "1 4 40\n",
      "0 3 41\n",
      "0 3 42\n",
      "1 18 34\n",
      "1 18 35\n",
      "1 15 36\n",
      "1 10 37\n",
      "0 3 38\n",
      "0 3 39\n",
      "1 5 37\n",
      "1 5 38\n",
      "1 3 39\n",
      "0 1 40\n",
      "1 2 39\n",
      "0 65 33\n",
      "0 62 34\n",
      "0 45 35\n",
      "0 41 36\n",
      "0 35 37\n",
      "0 19 38\n",
      "0 8 39\n",
      "0 4 40\n",
      "0 1 41\n",
      "1 7 40\n",
      "1 6 41\n",
      "1 4 42\n",
      "1 2 42\n",
      "0 11 39\n",
      "0 11 40\n",
      "0 11 41\n",
      "0 7 42\n",
      "0 16 38\n",
      "0 11 39\n",
      "0 9 40\n",
      "0 4 41\n",
      "1 4 42\n",
      "0 3 43\n",
      "0 2 44\n",
      "1 3 40\n",
      "0 2 41\n",
      "0 6 37\n",
      "0 5 38\n",
      "0 4 39\n",
      "0 2 40\n",
      "1 7 36\n",
      "1 6 37\n",
      "1 5 38\n",
      "1 2 39\n",
      "1 1 40\n",
      "0 3 37\n",
      "0 2 38\n",
      "0 17 35\n",
      "0 17 36\n",
      "0 12 37\n",
      "0 4 38\n",
      "1 1 39\n",
      "0 3 39\n",
      "0 5 37\n",
      "0 3 38\n",
      "0 2 38\n",
      "1 8 34\n",
      "0 3 35\n",
      "1 3 36\n",
      "0 1 37\n",
      "0 10 32\n",
      "0 7 33\n",
      "0 4 34\n",
      "0 2 35\n",
      "0 3 34\n",
      "1 2 35\n",
      "1 12 31\n",
      "1 3 32\n",
      "1 3 33\n",
      "1 9 32\n",
      "1 16 30\n",
      "1 14 31\n",
      "1 8 32\n",
      "0 3 33\n",
      "1 3 34\n",
      "0 2 35\n",
      "1 5 33\n",
      "1 2 34\n",
      "1 6 32\n",
      "1 5 33\n",
      "1 4 34\n",
      "1 2 31\n",
      "1 9 29\n",
      "0 5 30\n",
      "1 5 31\n",
      "1 5 32\n",
      "0 3 33\n",
      "1 4 30\n",
      "1 11 28\n",
      "1 6 29\n",
      "1 6 30\n",
      "1 5 31\n",
      "1 2 32\n",
      "1 5 27\n",
      "1 3 28\n",
      "1 3 29\n",
      "1 1 30\n",
      "1 7 26\n",
      "1 7 27\n",
      "1 7 28\n",
      "0 5 25\n",
      "0 5 26\n",
      "0 3 27\n",
      "1 2 24\n",
      "0 1 25\n",
      "1 3 22\n",
      "1 2 23\n",
      "1 2 24\n",
      "1 1 25\n",
      "1 6 21\n",
      "1 4 22\n",
      "1 2 23\n",
      "1 2 24\n",
      "1 3 20\n",
      "1 3 21\n",
      "1 2 22\n",
      "1 1 22\n",
      "1 11 19\n",
      "1 9 20\n",
      "0 4 21\n",
      "0 2 18\n",
      "0 2 19\n",
      "1 6 17\n",
      "0 2 18\n",
      "1 4 18\n",
      "1 2 19\n",
      "1 4 16\n",
      "1 4 13\n",
      "1 1 14\n",
      "1 2 12\n",
      "1 3 11\n",
      "1 3 12\n",
      "1 3 10\n",
      "1 3 9\n",
      "1 3 10\n",
      "1 1 11\n",
      "1 2 5\n",
      "0 488 0\n",
      "0 487 1\n",
      "0 486 2\n",
      "0 485 3\n",
      "0 481 4\n",
      "0 479 5\n",
      "0 477 6\n",
      "0 474 7\n",
      "0 473 8\n",
      "0 471 9\n",
      "0 471 10\n",
      "0 471 11\n",
      "0 470 12\n",
      "0 469 13\n",
      "0 466 14\n",
      "0 465 15\n",
      "0 463 16\n",
      "0 463 17\n",
      "0 462 18\n",
      "0 459 19\n",
      "0 456 20\n",
      "0 450 21\n",
      "0 448 22\n",
      "0 444 23\n",
      "0 440 24\n",
      "0 437 25\n",
      "0 434 26\n",
      "0 426 27\n",
      "0 422 28\n",
      "0 415 29\n",
      "0 408 30\n",
      "0 353 31\n",
      "0 341 32\n",
      "0 330 33\n",
      "0 322 34\n",
      "0 295 35\n",
      "0 269 36\n",
      "0 232 37\n",
      "0 189 38\n",
      "0 150 39\n",
      "0 126 40\n",
      "0 59 41\n",
      "0 51 42\n",
      "0 22 43\n",
      "0 18 44\n",
      "0 14 45\n",
      "0 12 46\n",
      "0 2 47\n",
      "0 2 46\n",
      "0 4 45\n",
      "0 2 46\n",
      "1 1 47\n",
      "0 67 41\n",
      "0 54 42\n",
      "0 18 43\n",
      "0 14 44\n",
      "0 12 45\n",
      "0 11 46\n",
      "0 9 47\n",
      "0 36 43\n",
      "0 23 44\n",
      "0 8 45\n",
      "0 3 46\n",
      "0 15 45\n",
      "1 13 44\n",
      "0 10 45\n",
      "0 8 46\n",
      "0 5 47\n",
      "0 4 48\n",
      "0 3 49\n",
      "1 11 45\n",
      "1 4 46\n",
      "1 1 47\n",
      "1 3 47\n",
      "1 3 48\n",
      "0 24 40\n",
      "0 4 41\n",
      "0 3 42\n",
      "0 1 43\n",
      "0 20 41\n",
      "0 13 42\n",
      "0 5 43\n",
      "0 2 44\n",
      "0 7 42\n",
      "1 3 43\n",
      "0 6 43\n",
      "0 5 44\n",
      "0 39 39\n",
      "0 29 40\n",
      "0 15 41\n",
      "0 10 42\n",
      "0 6 43\n",
      "0 4 44\n",
      "1 2 45\n",
      "0 5 42\n",
      "0 4 43\n",
      "0 3 44\n",
      "0 14 41\n",
      "0 11 42\n",
      "0 6 43\n",
      "0 2 44\n",
      "1 1 45\n",
      "0 10 40\n",
      "0 4 41\n",
      "1 2 42\n",
      "0 3 42\n",
      "0 2 43\n",
      "0 2 44\n",
      "0 1 45\n",
      "0 43 38\n",
      "0 11 39\n",
      "0 4 40\n",
      "0 2 41\n",
      "0 7 40\n",
      "0 6 41\n",
      "0 32 39\n",
      "0 31 40\n",
      "0 25 41\n",
      "0 12 42\n",
      "1 7 43\n",
      "0 6 44\n",
      "1 4 45\n",
      "0 13 42\n",
      "0 6 43\n",
      "0 3 44\n",
      "1 11 43\n",
      "1 4 44\n",
      "0 2 45\n",
      "1 3 45\n",
      "1 2 46\n",
      "1 7 44\n",
      "0 37 37\n",
      "0 23 38\n",
      "0 8 39\n",
      "0 6 40\n",
      "0 4 41\n",
      "1 3 42\n",
      "1 3 43\n",
      "0 15 39\n",
      "0 12 40\n",
      "0 9 41\n",
      "0 4 42\n",
      "0 14 38\n",
      "0 11 39\n",
      "0 4 40\n",
      "1 2 41\n",
      "0 3 39\n",
      "0 26 36\n",
      "0 14 37\n",
      "0 12 38\n",
      "0 9 39\n",
      "0 4 40\n",
      "0 3 41\n",
      "0 2 42\n",
      "0 2 43\n",
      "0 12 37\n",
      "1 8 38\n",
      "0 7 39\n",
      "1 6 40\n",
      "0 6 41\n",
      "1 4 42\n",
      "0 5 38\n",
      "0 4 39\n",
      "1 2 40\n",
      "0 27 35\n",
      "0 9 36\n",
      "0 7 37\n",
      "0 4 38\n",
      "1 3 39\n",
      "1 2 40\n",
      "1 1 40\n",
      "0 18 36\n",
      "0 17 37\n",
      "0 17 38\n",
      "0 7 39\n",
      "0 4 40\n",
      "1 1 41\n",
      "0 10 39\n",
      "0 4 40\n",
      "0 6 40\n",
      "1 13 34\n",
      "1 5 35\n",
      "1 3 36\n",
      "1 2 36\n",
      "1 8 35\n",
      "0 5 36\n",
      "0 3 37\n",
      "0 2 37\n",
      "0 2 38\n",
      "0 11 33\n",
      "0 10 34\n",
      "0 7 35\n",
      "0 2 36\n",
      "0 5 36\n",
      "0 2 37\n",
      "1 2 38\n",
      "1 3 34\n",
      "1 2 35\n",
      "1 15 32\n",
      "0 1 33\n",
      "1 14 33\n",
      "0 7 34\n",
      "0 1 35\n",
      "0 6 35\n",
      "1 4 36\n",
      "1 2 37\n",
      "1 9 34\n",
      "1 7 35\n",
      "1 7 36\n",
      "1 5 37\n",
      "1 2 35\n",
      "0 55 31\n",
      "0 48 32\n",
      "0 37 33\n",
      "0 30 34\n",
      "0 25 35\n",
      "1 21 36\n",
      "0 8 37\n",
      "0 7 38\n",
      "1 6 38\n",
      "0 1 39\n",
      "1 14 37\n",
      "0 3 38\n",
      "0 2 39\n",
      "0 2 40\n",
      "0 1 41\n",
      "1 12 38\n",
      "1 2 39\n",
      "0 2 40\n",
      "0 12 36\n",
      "0 3 37\n",
      "0 2 38\n",
      "1 1 39\n",
      "1 1 38\n",
      "0 5 35\n",
      "0 4 36\n",
      "1 1 36\n",
      "1 9 34\n",
      "1 7 35\n",
      "1 6 36\n",
      "1 5 37\n",
      "1 3 38\n",
      "0 4 35\n",
      "0 2 36\n",
      "0 11 33\n",
      "0 9 34\n",
      "0 8 35\n",
      "0 5 36\n",
      "0 4 37\n",
      "1 1 37\n",
      "1 11 32\n",
      "1 8 33\n",
      "0 6 34\n",
      "0 6 35\n",
      "1 3 34\n",
      "0 7 30\n",
      "0 3 31\n",
      "0 1 32\n",
      "0 7 29\n",
      "1 4 30\n",
      "1 4 31\n",
      "1 14 28\n",
      "1 9 29\n",
      "1 7 30\n",
      "1 3 31\n",
      "1 2 32\n",
      "1 4 31\n",
      "1 3 32\n",
      "1 5 29\n",
      "0 2 30\n",
      "1 2 31\n",
      "0 8 27\n",
      "1 5 28\n",
      "1 5 29\n",
      "1 1 30\n",
      "1 4 30\n",
      "1 16 26\n",
      "1 11 27\n",
      "1 2 28\n",
      "1 5 27\n",
      "1 3 28\n",
      "0 2 29\n",
      "1 8 25\n",
      "0 3 26\n",
      "1 7 24\n",
      "1 10 23\n",
      "0 2 24\n",
      "0 1 25\n",
      "1 9 24\n",
      "1 8 25\n",
      "1 3 26\n",
      "1 1 25\n",
      "1 2 22\n",
      "0 6 21\n",
      "0 5 22\n",
      "0 4 23\n",
      "0 2 24\n",
      "0 3 20\n",
      "0 3 21\n",
      "1 9 19\n",
      "1 2 20\n",
      "1 7 20\n",
      "1 7 21\n",
      "1 5 18\n",
      "1 3 19\n",
      "1 2 16\n",
      "0 2 17\n",
      "1 5 15\n",
      "1 4 16\n",
      "0 3 14\n",
      "0 2 15\n",
      "0 1 13\n",
      "1 1 12\n",
      "0 2 9\n",
      "0 1 10\n",
      "1 3 8\n",
      "0 4 4\n",
      "0 4 5\n",
      "0 3 6\n",
      "0 1 3\n",
      "0 497 0\n",
      "0 496 1\n",
      "0 495 2\n",
      "0 493 3\n",
      "0 493 4\n",
      "0 490 5\n",
      "0 488 6\n",
      "0 487 7\n",
      "0 484 8\n",
      "0 479 9\n",
      "0 478 10\n",
      "0 475 11\n",
      "0 468 12\n",
      "0 466 13\n",
      "0 464 14\n",
      "0 461 15\n",
      "0 459 16\n",
      "0 459 17\n",
      "0 454 18\n",
      "0 451 19\n",
      "0 449 20\n",
      "0 443 21\n",
      "0 442 22\n",
      "0 441 23\n",
      "0 434 24\n",
      "0 432 25\n",
      "0 431 26\n",
      "0 419 27\n",
      "0 411 28\n",
      "0 401 29\n",
      "0 396 30\n",
      "0 334 31\n",
      "0 328 32\n",
      "0 309 33\n",
      "0 293 34\n",
      "0 275 35\n",
      "0 257 36\n",
      "0 231 37\n",
      "0 203 38\n",
      "0 153 39\n",
      "0 115 40\n",
      "0 51 41\n",
      "0 40 42\n",
      "0 29 43\n",
      "0 17 44\n",
      "0 16 45\n",
      "0 10 46\n",
      "0 3 47\n",
      "0 7 47\n",
      "0 3 48\n",
      "1 2 49\n",
      "1 2 50\n",
      "0 6 46\n",
      "0 5 47\n",
      "0 3 48\n",
      "0 2 49\n",
      "0 64 41\n",
      "0 33 42\n",
      "0 29 43\n",
      "0 24 44\n",
      "0 21 45\n",
      "0 20 46\n",
      "0 19 47\n",
      "0 15 48\n",
      "0 6 49\n",
      "0 5 50\n",
      "0 3 51\n",
      "0 5 44\n",
      "0 4 45\n",
      "1 3 46\n",
      "1 3 47\n",
      "0 31 42\n",
      "0 24 43\n",
      "0 20 44\n",
      "0 18 45\n",
      "0 12 46\n",
      "0 3 47\n",
      "0 6 46\n",
      "0 2 47\n",
      "1 1 48\n",
      "1 6 44\n",
      "1 6 45\n",
      "1 5 46\n",
      "0 3 47\n",
      "0 38 40\n",
      "0 6 41\n",
      "0 5 42\n",
      "1 3 43\n",
      "1 3 44\n",
      "1 3 45\n",
      "0 32 41\n",
      "0 30 42\n",
      "0 17 43\n",
      "0 6 44\n",
      "0 4 45\n",
      "0 1 46\n",
      "0 13 43\n",
      "0 7 44\n",
      "0 6 45\n",
      "0 3 46\n",
      "1 4 45\n",
      "1 3 46\n",
      "0 50 39\n",
      "0 37 40\n",
      "0 30 41\n",
      "0 29 42\n",
      "0 26 43\n",
      "0 19 44\n",
      "0 10 45\n",
      "0 9 46\n",
      "1 5 47\n",
      "0 9 45\n",
      "0 7 46\n",
      "0 3 47\n",
      "0 2 48\n",
      "0 3 43\n",
      "0 13 40\n",
      "1 4 41\n",
      "1 3 42\n",
      "0 11 41\n",
      "0 9 42\n",
      "0 28 38\n",
      "0 5 39\n",
      "0 2 40\n",
      "0 1 41\n",
      "0 3 40\n",
      "0 23 39\n",
      "0 13 40\n",
      "0 11 41\n",
      "0 8 42\n",
      "0 5 43\n",
      "0 4 44\n",
      "1 4 43\n",
      "1 4 44\n",
      "1 3 45\n",
      "0 10 40\n",
      "0 2 41\n",
      "0 8 41\n",
      "1 3 42\n",
      "0 7 42\n",
      "0 7 43\n",
      "0 2 44\n",
      "0 26 37\n",
      "0 26 38\n",
      "0 19 39\n",
      "0 16 40\n",
      "0 16 41\n",
      "0 11 42\n",
      "0 6 43\n",
      "1 2 44\n",
      "0 7 39\n",
      "0 6 40\n",
      "0 18 36\n",
      "0 16 37\n",
      "0 9 38\n",
      "0 3 39\n",
      "1 2 40\n",
      "1 2 41\n",
      "0 6 39\n",
      "1 5 40\n",
      "1 5 41\n",
      "0 2 37\n",
      "1 2 38\n",
      "0 1 39\n",
      "0 18 35\n",
      "0 13 36\n",
      "0 8 37\n",
      "0 3 38\n",
      "0 5 37\n",
      "0 4 38\n",
      "1 3 39\n",
      "1 5 36\n",
      "0 5 37\n",
      "0 2 38\n",
      "1 2 39\n",
      "0 3 38\n",
      "1 2 39\n",
      "0 16 34\n",
      "0 10 35\n",
      "0 3 36\n",
      "0 2 37\n",
      "0 1 38\n",
      "0 7 36\n",
      "0 4 37\n",
      "0 2 38\n",
      "1 11 35\n",
      "1 9 36\n",
      "1 9 37\n",
      "1 4 38\n",
      "1 4 39\n",
      "1 2 36\n",
      "1 1 37\n",
      "0 19 33\n",
      "0 17 34\n",
      "0 7 35\n",
      "0 3 36\n",
      "0 10 35\n",
      "0 9 36\n",
      "0 9 37\n",
      "0 9 38\n",
      "0 3 39\n",
      "1 10 32\n",
      "1 10 33\n",
      "1 3 34\n",
      "1 7 34\n",
      "1 3 35\n",
      "0 2 36\n",
      "1 2 37\n",
      "1 1 36\n",
      "1 4 35\n",
      "0 62 31\n",
      "0 54 32\n",
      "0 42 33\n",
      "0 33 34\n",
      "0 30 35\n",
      "0 17 36\n",
      "0 7 37\n",
      "1 5 38\n",
      "0 5 39\n",
      "1 12 37\n",
      "0 9 38\n",
      "0 2 39\n",
      "0 2 40\n",
      "0 1 41\n",
      "1 10 38\n",
      "1 4 39\n",
      "1 3 40\n",
      "0 13 36\n",
      "0 5 37\n",
      "1 2 38\n",
      "0 3 35\n",
      "0 3 36\n",
      "0 9 34\n",
      "0 9 35\n",
      "1 6 36\n",
      "1 5 37\n",
      "0 2 37\n",
      "0 12 33\n",
      "0 6 34\n",
      "0 2 35\n",
      "0 6 34\n",
      "0 5 35\n",
      "0 5 36\n",
      "0 4 37\n",
      "1 12 32\n",
      "0 8 33\n",
      "0 5 34\n",
      "0 2 35\n",
      "0 2 36\n",
      "1 5 34\n",
      "0 5 30\n",
      "0 5 31\n",
      "1 2 32\n",
      "1 2 33\n",
      "0 10 29\n",
      "0 10 30\n",
      "0 8 31\n",
      "0 6 32\n",
      "0 2 33\n",
      "0 4 33\n",
      "1 16 28\n",
      "1 9 29\n",
      "0 1 30\n",
      "1 8 30\n",
      "1 5 31\n",
      "1 7 29\n",
      "1 6 30\n",
      "1 2 31\n",
      "1 4 31\n",
      "0 2 30\n",
      "1 13 27\n",
      "0 4 28\n",
      "1 3 29\n",
      "1 3 30\n",
      "1 10 28\n",
      "1 2 29\n",
      "1 8 29\n",
      "1 3 30\n",
      "1 5 30\n",
      "1 3 31\n",
      "0 3 31\n",
      "1 2 32\n",
      "1 14 26\n",
      "1 3 27\n",
      "1 5 25\n",
      "1 3 26\n",
      "1 3 27\n",
      "1 10 24\n",
      "1 10 25\n",
      "1 7 26\n",
      "1 7 27\n",
      "1 6 28\n",
      "0 5 29\n",
      "1 3 30\n",
      "0 2 30\n",
      "1 10 23\n",
      "1 7 24\n",
      "1 4 25\n",
      "1 3 22\n",
      "1 2 23\n",
      "0 1 24\n",
      "0 2 20\n",
      "0 2 21\n",
      "1 4 19\n",
      "0 3 20\n",
      "1 2 21\n",
      "0 5 18\n",
      "1 4 19\n",
      "1 2 20\n",
      "1 3 16\n",
      "1 5 15\n",
      "0 3 16\n",
      "0 2 14\n",
      "0 7 12\n",
      "0 4 13\n",
      "0 2 14\n",
      "0 3 11\n",
      "1 2 12\n",
      "1 2 10\n",
      "0 5 9\n",
      "1 1 10\n",
      "0 4 10\n",
      "0 3 8\n",
      "0 1 7\n",
      "0 508 0\n",
      "0 506 1\n",
      "0 506 2\n",
      "0 504 3\n",
      "0 503 4\n",
      "0 503 5\n",
      "0 501 6\n",
      "0 496 7\n",
      "0 495 8\n",
      "0 494 9\n",
      "0 494 10\n",
      "0 493 11\n",
      "0 486 12\n",
      "0 482 13\n",
      "0 482 14\n",
      "0 476 15\n",
      "0 473 16\n",
      "0 471 17\n",
      "0 468 18\n",
      "0 467 19\n",
      "0 467 20\n",
      "0 465 21\n",
      "0 462 22\n",
      "0 460 23\n",
      "0 452 24\n",
      "0 444 25\n",
      "0 442 26\n",
      "0 440 27\n",
      "0 432 28\n",
      "0 423 29\n",
      "0 411 30\n",
      "0 402 31\n",
      "0 341 32\n",
      "0 332 33\n",
      "0 320 34\n",
      "0 305 35\n",
      "0 284 36\n",
      "0 260 37\n",
      "0 234 38\n",
      "0 192 39\n",
      "0 156 40\n",
      "0 119 41\n",
      "0 69 42\n",
      "0 67 43\n",
      "0 62 44\n",
      "0 53 45\n",
      "0 50 46\n",
      "0 39 47\n",
      "0 32 48\n",
      "0 17 49\n",
      "0 16 50\n",
      "0 9 51\n",
      "0 4 52\n",
      "1 2 53\n",
      "0 15 49\n",
      "0 13 50\n",
      "1 3 51\n",
      "1 2 52\n",
      "0 3 46\n",
      "0 5 44\n",
      "1 2 45\n",
      "0 50 42\n",
      "0 31 43\n",
      "0 25 44\n",
      "0 24 45\n",
      "0 22 46\n",
      "0 19 47\n",
      "0 14 48\n",
      "0 10 49\n",
      "0 5 48\n",
      "0 4 49\n",
      "1 2 49\n",
      "0 19 43\n",
      "0 16 44\n",
      "0 11 45\n",
      "0 5 46\n",
      "1 2 47\n",
      "0 3 44\n",
      "0 37 41\n",
      "0 31 42\n",
      "0 30 43\n",
      "0 8 44\n",
      "0 7 45\n",
      "0 22 44\n",
      "0 14 45\n",
      "0 12 46\n",
      "0 8 47\n",
      "0 6 48\n",
      "0 4 49\n",
      "0 6 42\n",
      "0 3 43\n",
      "0 36 40\n",
      "0 31 41\n",
      "0 8 42\n",
      "0 5 43\n",
      "0 4 44\n",
      "0 23 42\n",
      "0 22 43\n",
      "0 19 44\n",
      "0 18 45\n",
      "0 14 46\n",
      "0 10 47\n",
      "0 6 48\n",
      "0 4 49\n",
      "0 5 41\n",
      "1 4 42\n",
      "1 2 43\n",
      "0 42 39\n",
      "0 6 40\n",
      "0 3 41\n",
      "0 36 40\n",
      "0 18 41\n",
      "0 10 42\n",
      "0 5 43\n",
      "0 18 41\n",
      "0 18 42\n",
      "0 8 43\n",
      "0 5 44\n",
      "0 2 45\n",
      "0 3 44\n",
      "0 26 38\n",
      "0 25 39\n",
      "0 15 40\n",
      "0 9 41\n",
      "1 4 42\n",
      "1 3 43\n",
      "1 1 43\n",
      "0 10 40\n",
      "0 10 41\n",
      "0 8 42\n",
      "0 3 43\n",
      "1 2 44\n",
      "0 1 39\n",
      "0 24 37\n",
      "0 21 38\n",
      "0 10 39\n",
      "0 7 40\n",
      "1 5 41\n",
      "1 5 42\n",
      "1 1 43\n",
      "0 11 39\n",
      "0 5 40\n",
      "1 3 41\n",
      "0 21 36\n",
      "0 10 37\n",
      "0 6 38\n",
      "1 3 39\n",
      "1 3 40\n",
      "0 3 39\n",
      "0 2 40\n",
      "1 1 40\n",
      "0 11 37\n",
      "0 9 38\n",
      "0 9 39\n",
      "0 5 40\n",
      "0 2 41\n",
      "0 15 35\n",
      "0 3 36\n",
      "0 1 37\n",
      "0 12 36\n",
      "0 5 37\n",
      "0 7 37\n",
      "1 7 38\n",
      "1 5 39\n",
      "1 2 39\n",
      "0 12 34\n",
      "0 12 35\n",
      "0 10 36\n",
      "0 9 37\n",
      "0 3 38\n",
      "1 2 39\n",
      "1 20 33\n",
      "1 1 34\n",
      "1 19 34\n",
      "1 11 35\n",
      "0 2 36\n",
      "1 8 35\n",
      "0 6 36\n",
      "1 4 37\n",
      "1 1 38\n",
      "0 5 37\n",
      "0 3 38\n",
      "0 61 32\n",
      "0 52 33\n",
      "0 36 34\n",
      "0 27 35\n",
      "0 25 36\n",
      "1 12 37\n",
      "0 6 38\n",
      "0 4 39\n",
      "0 2 40\n",
      "1 3 39\n",
      "0 2 40\n",
      "1 8 38\n",
      "1 5 39\n",
      "1 5 40\n",
      "0 4 41\n",
      "1 2 42\n",
      "0 14 37\n",
      "0 8 38\n",
      "0 4 39\n",
      "0 4 39\n",
      "0 3 40\n",
      "0 6 38\n",
      "1 4 39\n",
      "0 2 36\n",
      "0 2 37\n",
      "0 9 35\n",
      "1 1 36\n",
      "0 8 36\n",
      "1 5 37\n",
      "0 5 38\n",
      "0 2 39\n",
      "1 3 39\n",
      "0 3 40\n",
      "0 3 37\n",
      "0 16 34\n",
      "0 8 35\n",
      "0 6 36\n",
      "0 5 37\n",
      "1 2 37\n",
      "0 8 35\n",
      "0 5 36\n",
      "0 3 36\n",
      "0 9 33\n",
      "0 7 34\n",
      "0 7 35\n",
      "0 5 36\n",
      "0 5 37\n",
      "0 2 38\n",
      "1 3 34\n",
      "0 2 35\n",
      "0 2 36\n",
      "0 9 31\n",
      "0 8 32\n",
      "0 5 33\n",
      "0 4 34\n",
      "1 2 32\n",
      "0 12 30\n",
      "0 8 31\n",
      "0 4 31\n",
      "0 3 32\n",
      "0 3 33\n",
      "0 1 34\n",
      "0 9 29\n",
      "1 5 30\n",
      "1 2 31\n",
      "0 7 30\n",
      "0 5 31\n",
      "0 4 32\n",
      "1 3 32\n",
      "1 1 33\n",
      "0 8 28\n",
      "0 3 29\n",
      "0 3 30\n",
      "0 2 31\n",
      "0 1 32\n",
      "1 15 27\n",
      "1 11 28\n",
      "1 3 29\n",
      "1 8 26\n",
      "1 6 27\n",
      "1 6 28\n",
      "1 5 29\n",
      "1 14 25\n",
      "1 5 26\n",
      "0 3 27\n",
      "1 3 27\n",
      "1 3 28\n",
      "1 9 26\n",
      "1 5 27\n",
      "0 3 28\n",
      "1 9 24\n",
      "1 9 25\n",
      "1 7 26\n",
      "1 6 27\n",
      "0 3 28\n",
      "1 2 26\n",
      "1 7 23\n",
      "1 3 24\n",
      "0 2 25\n",
      "0 3 22\n",
      "1 3 21\n",
      "0 2 22\n",
      "1 6 19\n",
      "1 4 20\n",
      "1 2 21\n",
      "1 11 18\n",
      "1 5 19\n",
      "1 3 20\n",
      "1 7 17\n",
      "1 6 18\n",
      "1 4 19\n",
      "0 2 20\n",
      "1 5 16\n",
      "1 2 17\n",
      "0 2 18\n",
      "1 3 17\n",
      "1 2 18\n",
      "0 4 13\n",
      "0 2 14\n",
      "1 2 15\n",
      "0 7 12\n",
      "0 4 13\n",
      "1 2 11\n",
      "1 2 9\n",
      "0 488 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 487 1\n",
      "0 485 2\n",
      "0 482 3\n",
      "0 480 4\n",
      "0 479 5\n",
      "0 477 6\n",
      "0 476 7\n",
      "0 470 8\n",
      "0 470 9\n",
      "0 469 10\n",
      "0 467 11\n",
      "0 467 12\n",
      "0 462 13\n",
      "0 461 14\n",
      "0 461 15\n",
      "0 459 16\n",
      "0 457 17\n",
      "0 457 18\n",
      "0 456 19\n",
      "0 455 20\n",
      "0 450 21\n",
      "0 449 22\n",
      "0 446 23\n",
      "0 444 24\n",
      "0 441 25\n",
      "0 436 26\n",
      "0 433 27\n",
      "0 433 28\n",
      "0 421 29\n",
      "0 408 30\n",
      "0 400 31\n",
      "0 389 32\n",
      "0 333 33\n",
      "0 320 34\n",
      "0 300 35\n",
      "0 287 36\n",
      "0 270 37\n",
      "0 241 38\n",
      "0 218 39\n",
      "0 192 40\n",
      "0 148 41\n",
      "0 116 42\n",
      "0 61 43\n",
      "0 60 44\n",
      "0 30 45\n",
      "0 28 46\n",
      "0 22 47\n",
      "0 6 48\n",
      "0 5 49\n",
      "0 1 50\n",
      "0 30 45\n",
      "0 23 46\n",
      "0 19 47\n",
      "0 17 48\n",
      "0 7 49\n",
      "0 2 50\n",
      "1 1 51\n",
      "0 2 48\n",
      "0 1 49\n",
      "0 55 43\n",
      "0 27 44\n",
      "0 22 45\n",
      "0 15 46\n",
      "0 9 47\n",
      "0 8 48\n",
      "0 7 49\n",
      "0 6 50\n",
      "0 3 51\n",
      "1 2 52\n",
      "0 28 44\n",
      "0 10 45\n",
      "0 9 46\n",
      "0 7 47\n",
      "0 6 48\n",
      "1 2 49\n",
      "1 4 46\n",
      "0 18 45\n",
      "0 13 46\n",
      "0 9 47\n",
      "0 4 48\n",
      "1 2 49\n",
      "0 4 47\n",
      "0 2 48\n",
      "0 5 46\n",
      "0 32 42\n",
      "0 19 43\n",
      "0 8 44\n",
      "0 7 45\n",
      "0 2 46\n",
      "0 5 46\n",
      "0 2 47\n",
      "0 11 44\n",
      "0 7 45\n",
      "1 4 46\n",
      "1 4 47\n",
      "1 3 48\n",
      "1 3 49\n",
      "0 44 41\n",
      "0 34 42\n",
      "0 14 43\n",
      "0 11 44\n",
      "0 10 45\n",
      "1 3 46\n",
      "1 3 47\n",
      "1 2 45\n",
      "0 10 42\n",
      "0 3 43\n",
      "0 3 44\n",
      "0 26 40\n",
      "0 25 41\n",
      "0 18 42\n",
      "0 5 43\n",
      "0 4 44\n",
      "0 2 45\n",
      "0 1 44\n",
      "0 13 43\n",
      "0 8 44\n",
      "0 5 45\n",
      "0 1 46\n",
      "0 7 42\n",
      "0 5 43\n",
      "0 2 44\n",
      "0 1 45\n",
      "0 3 44\n",
      "0 2 43\n",
      "1 3 41\n",
      "1 2 42\n",
      "0 23 39\n",
      "0 17 40\n",
      "0 8 41\n",
      "0 6 42\n",
      "0 6 43\n",
      "0 4 44\n",
      "0 2 45\n",
      "0 2 44\n",
      "0 6 40\n",
      "0 29 38\n",
      "0 15 39\n",
      "1 9 40\n",
      "1 9 41\n",
      "1 9 42\n",
      "1 7 43\n",
      "1 5 44\n",
      "0 2 43\n",
      "0 14 39\n",
      "0 14 40\n",
      "0 11 41\n",
      "0 9 42\n",
      "0 3 41\n",
      "0 2 42\n",
      "0 1 42\n",
      "0 17 37\n",
      "0 11 38\n",
      "0 10 39\n",
      "0 7 40\n",
      "0 5 41\n",
      "1 4 42\n",
      "1 4 43\n",
      "1 3 41\n",
      "1 1 39\n",
      "0 6 38\n",
      "1 3 39\n",
      "1 3 40\n",
      "0 4 39\n",
      "0 3 40\n",
      "1 1 40\n",
      "1 18 36\n",
      "1 6 37\n",
      "0 4 38\n",
      "0 4 39\n",
      "1 4 38\n",
      "1 12 37\n",
      "1 3 38\n",
      "1 1 39\n",
      "1 9 38\n",
      "1 3 39\n",
      "1 3 40\n",
      "1 2 41\n",
      "1 6 39\n",
      "1 2 40\n",
      "1 4 40\n",
      "0 2 41\n",
      "0 20 35\n",
      "0 19 36\n",
      "0 13 37\n",
      "0 12 38\n",
      "0 7 39\n",
      "0 5 40\n",
      "0 6 37\n",
      "0 3 38\n",
      "1 14 34\n",
      "1 11 35\n",
      "1 10 36\n",
      "0 5 37\n",
      "0 3 38\n",
      "0 1 36\n",
      "0 7 35\n",
      "0 6 36\n",
      "0 3 37\n",
      "1 2 36\n",
      "1 62 33\n",
      "1 51 34\n",
      "1 42 35\n",
      "1 33 36\n",
      "1 25 37\n",
      "1 22 38\n",
      "1 11 39\n",
      "0 5 40\n",
      "0 5 41\n",
      "0 4 42\n",
      "0 1 43\n",
      "1 11 39\n",
      "0 5 40\n",
      "0 2 41\n",
      "1 10 40\n",
      "1 8 41\n",
      "1 4 42\n",
      "0 1 43\n",
      "1 4 42\n",
      "1 3 43\n",
      "0 10 38\n",
      "0 3 39\n",
      "0 1 40\n",
      "0 7 39\n",
      "0 6 40\n",
      "0 4 41\n",
      "0 3 42\n",
      "1 8 37\n",
      "1 7 38\n",
      "1 4 39\n",
      "1 3 40\n",
      "0 5 38\n",
      "0 3 39\n",
      "1 9 36\n",
      "1 5 37\n",
      "1 4 38\n",
      "1 3 39\n",
      "1 2 40\n",
      "1 2 41\n",
      "0 5 37\n",
      "0 5 38\n",
      "1 3 39\n",
      "1 3 40\n",
      "0 12 35\n",
      "0 9 36\n",
      "0 8 37\n",
      "0 8 38\n",
      "0 7 39\n",
      "1 3 40\n",
      "1 4 36\n",
      "1 11 34\n",
      "1 10 35\n",
      "0 4 36\n",
      "0 4 37\n",
      "0 3 38\n",
      "1 8 36\n",
      "0 11 32\n",
      "0 10 33\n",
      "0 5 34\n",
      "0 2 35\n",
      "0 5 34\n",
      "1 3 35\n",
      "0 8 31\n",
      "0 7 32\n",
      "0 1 33\n",
      "0 6 33\n",
      "0 2 34\n",
      "0 2 35\n",
      "0 13 30\n",
      "1 10 31\n",
      "0 10 32\n",
      "1 9 33\n",
      "0 9 34\n",
      "0 9 35\n",
      "0 4 36\n",
      "0 3 37\n",
      "0 5 36\n",
      "1 4 37\n",
      "1 2 38\n",
      "0 1 39\n",
      "0 12 29\n",
      "0 11 30\n",
      "0 7 31\n",
      "0 5 32\n",
      "0 2 32\n",
      "0 4 31\n",
      "0 4 32\n",
      "0 2 33\n",
      "1 3 27\n",
      "1 3 28\n",
      "1 3 29\n",
      "1 2 30\n",
      "1 1 31\n",
      "1 8 26\n",
      "1 6 27\n",
      "1 6 28\n",
      "1 2 27\n",
      "1 7 25\n",
      "1 2 26\n",
      "1 5 26\n",
      "1 4 27\n",
      "1 2 28\n",
      "0 1 27\n",
      "1 5 24\n",
      "0 2 25\n",
      "1 10 22\n",
      "1 9 23\n",
      "1 7 24\n",
      "1 9 21\n",
      "0 5 22\n",
      "1 8 20\n",
      "1 5 21\n",
      "1 1 22\n",
      "1 4 19\n",
      "1 3 20\n",
      "1 3 17\n",
      "0 1 14\n",
      "0 5 13\n",
      "0 2 14\n",
      "0 3 14\n",
      "0 3 15\n",
      "1 2 10\n",
      "1 2 5\n",
      "0 494 0\n",
      "0 493 1\n",
      "0 492 2\n",
      "0 491 3\n",
      "0 489 4\n",
      "0 486 5\n",
      "0 484 6\n",
      "0 483 7\n",
      "0 477 8\n",
      "0 476 9\n",
      "0 471 10\n",
      "0 469 11\n",
      "0 468 12\n",
      "0 462 13\n",
      "0 461 14\n",
      "0 457 15\n",
      "0 454 16\n",
      "0 451 17\n",
      "0 451 18\n",
      "0 447 19\n",
      "0 445 20\n",
      "0 442 21\n",
      "0 440 22\n",
      "0 436 23\n",
      "0 433 24\n",
      "0 418 25\n",
      "0 413 26\n",
      "0 412 27\n",
      "0 404 28\n",
      "0 395 29\n",
      "0 390 30\n",
      "0 375 31\n",
      "0 320 32\n",
      "0 311 33\n",
      "0 295 34\n",
      "0 279 35\n",
      "0 256 36\n",
      "0 231 37\n",
      "0 210 38\n",
      "0 181 39\n",
      "0 148 40\n",
      "0 120 41\n",
      "0 60 42\n",
      "0 58 43\n",
      "0 53 44\n",
      "0 33 45\n",
      "0 27 46\n",
      "0 17 47\n",
      "0 10 48\n",
      "0 2 49\n",
      "0 10 47\n",
      "0 9 48\n",
      "0 60 42\n",
      "0 31 43\n",
      "0 10 44\n",
      "0 5 45\n",
      "0 4 46\n",
      "0 29 43\n",
      "0 22 44\n",
      "0 21 45\n",
      "0 3 46\n",
      "0 2 47\n",
      "0 18 46\n",
      "0 16 47\n",
      "0 9 48\n",
      "0 7 49\n",
      "0 6 50\n",
      "0 7 48\n",
      "0 5 49\n",
      "0 3 50\n",
      "0 7 44\n",
      "0 1 45\n",
      "0 6 45\n",
      "1 2 46\n",
      "0 1 47\n",
      "0 28 41\n",
      "0 19 42\n",
      "0 11 43\n",
      "0 6 44\n",
      "0 4 45\n",
      "0 5 44\n",
      "0 1 45\n",
      "0 8 43\n",
      "1 4 44\n",
      "0 4 45\n",
      "1 3 46\n",
      "0 33 40\n",
      "0 26 41\n",
      "0 11 42\n",
      "0 5 43\n",
      "0 3 44\n",
      "0 2 45\n",
      "1 1 46\n",
      "0 15 42\n",
      "0 12 43\n",
      "0 9 44\n",
      "0 8 45\n",
      "0 8 46\n",
      "0 6 47\n",
      "0 3 48\n",
      "0 7 41\n",
      "1 4 42\n",
      "1 2 43\n",
      "0 3 43\n",
      "0 29 39\n",
      "0 18 40\n",
      "0 15 41\n",
      "0 11 42\n",
      "0 8 43\n",
      "0 7 44\n",
      "0 3 43\n",
      "0 2 44\n",
      "0 11 40\n",
      "0 4 41\n",
      "0 3 42\n",
      "1 2 43\n",
      "0 7 41\n",
      "0 6 42\n",
      "0 6 43\n",
      "0 21 38\n",
      "0 19 39\n",
      "0 12 40\n",
      "0 7 41\n",
      "0 6 42\n",
      "0 5 43\n",
      "0 4 44\n",
      "0 4 45\n",
      "0 1 42\n",
      "0 5 41\n",
      "0 4 42\n",
      "0 3 43\n",
      "0 7 40\n",
      "0 6 41\n",
      "0 4 42\n",
      "0 2 43\n",
      "0 25 37\n",
      "0 23 38\n",
      "0 17 39\n",
      "0 6 40\n",
      "0 5 41\n",
      "0 4 42\n",
      "0 4 43\n",
      "0 6 39\n",
      "1 5 40\n",
      "0 4 41\n",
      "1 4 42\n",
      "0 2 40\n",
      "0 1 41\n",
      "0 23 36\n",
      "0 20 37\n",
      "0 11 38\n",
      "0 7 39\n",
      "1 3 40\n",
      "1 3 41\n",
      "1 1 42\n",
      "0 5 40\n",
      "1 3 41\n",
      "0 9 38\n",
      "0 6 39\n",
      "0 6 40\n",
      "0 5 41\n",
      "0 4 42\n",
      "1 3 43\n",
      "1 6 37\n",
      "1 1 38\n",
      "1 5 38\n",
      "0 2 39\n",
      "0 16 35\n",
      "0 12 36\n",
      "0 9 37\n",
      "0 7 38\n",
      "0 5 39\n",
      "0 3 40\n",
      "1 5 38\n",
      "1 5 39\n",
      "1 3 37\n",
      "1 3 38\n",
      "1 2 39\n",
      "1 7 36\n",
      "1 7 37\n",
      "1 5 38\n",
      "1 5 39\n",
      "1 3 40\n",
      "0 16 34\n",
      "0 12 35\n",
      "0 9 36\n",
      "1 2 37\n",
      "1 2 38\n",
      "0 7 37\n",
      "0 5 38\n",
      "1 8 36\n",
      "1 12 33\n",
      "1 10 34\n",
      "0 3 35\n",
      "0 2 36\n",
      "1 9 35\n",
      "1 8 36\n",
      "0 5 34\n",
      "0 4 35\n",
      "0 2 36\n",
      "0 1 35\n",
      "0 55 32\n",
      "0 52 33\n",
      "0 42 34\n",
      "0 33 35\n",
      "0 27 36\n",
      "0 16 37\n",
      "0 11 38\n",
      "0 10 39\n",
      "0 6 40\n",
      "0 4 41\n",
      "0 2 42\n",
      "0 4 40\n",
      "0 2 41\n",
      "0 2 41\n",
      "1 2 42\n",
      "0 1 43\n",
      "1 6 38\n",
      "0 4 39\n",
      "0 3 40\n",
      "0 1 40\n",
      "1 3 39\n",
      "1 2 40\n",
      "1 1 41\n",
      "0 11 37\n",
      "0 8 38\n",
      "0 5 39\n",
      "0 2 40\n",
      "1 4 39\n",
      "0 3 40\n",
      "1 7 36\n",
      "1 7 37\n",
      "1 6 38\n",
      "1 4 39\n",
      "1 1 40\n",
      "0 2 39\n",
      "1 10 35\n",
      "0 9 36\n",
      "1 6 37\n",
      "0 2 38\n",
      "1 4 38\n",
      "0 5 37\n",
      "0 3 38\n",
      "0 2 39\n",
      "0 10 34\n",
      "0 7 35\n",
      "0 6 36\n",
      "0 3 35\n",
      "0 2 36\n",
      "0 2 37\n",
      "0 1 38\n",
      "1 10 33\n",
      "1 9 34\n",
      "1 6 35\n",
      "1 3 36\n",
      "1 3 37\n",
      "1 2 38\n",
      "0 15 31\n",
      "0 14 32\n",
      "0 11 33\n",
      "0 6 34\n",
      "0 5 35\n",
      "0 2 36\n",
      "1 5 33\n",
      "1 10 30\n",
      "1 3 31\n",
      "1 7 31\n",
      "1 7 32\n",
      "0 2 33\n",
      "1 1 34\n",
      "1 6 33\n",
      "1 4 34\n",
      "0 1 35\n",
      "1 16 29\n",
      "1 6 30\n",
      "1 10 30\n",
      "1 10 31\n",
      "1 7 32\n",
      "1 7 33\n",
      "1 5 34\n",
      "1 3 32\n",
      "0 2 33\n",
      "0 8 28\n",
      "0 7 29\n",
      "1 4 30\n",
      "1 4 31\n",
      "1 11 27\n",
      "1 10 28\n",
      "1 9 29\n",
      "1 5 30\n",
      "1 4 31\n",
      "1 1 32\n",
      "0 5 26\n",
      "0 1 27\n",
      "0 4 27\n",
      "1 1 28\n",
      "0 15 25\n",
      "0 13 26\n",
      "0 7 27\n",
      "1 7 27\n",
      "0 6 28\n",
      "1 4 29\n",
      "1 3 30\n",
      "1 11 24\n",
      "1 5 25\n",
      "0 1 26\n",
      "1 4 26\n",
      "1 6 25\n",
      "1 4 26\n",
      "1 2 27\n",
      "0 4 23\n",
      "1 3 22\n",
      "0 3 21\n",
      "0 3 22\n",
      "0 2 23\n",
      "1 5 20\n",
      "1 3 21\n",
      "1 4 19\n",
      "0 4 20\n",
      "0 3 21\n",
      "1 1 22\n",
      "1 5 17\n",
      "0 3 18\n",
      "1 6 16\n",
      "0 2 17\n",
      "1 5 17\n",
      "1 3 18\n",
      "0 4 15\n",
      "1 3 16\n",
      "1 3 17\n",
      "1 3 14\n",
      "0 6 13\n",
      "1 3 14\n",
      "1 4 12\n",
      "0 1 13\n",
      "0 2 11\n",
      "0 5 10\n",
      "1 2 9\n",
      "1 1 10\n",
      "1 5 5\n",
      "1 5 6\n",
      "1 2 7\n",
      "0 2 4\n",
      "0 489 0\n",
      "0 487 1\n",
      "0 487 2\n",
      "0 486 3\n",
      "0 484 4\n",
      "0 483 5\n",
      "0 481 6\n",
      "0 480 7\n",
      "0 477 8\n",
      "0 477 9\n",
      "0 476 10\n",
      "0 474 11\n",
      "0 473 12\n",
      "0 470 13\n",
      "0 467 14\n",
      "0 466 15\n",
      "0 464 16\n",
      "0 461 17\n",
      "0 460 18\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Late Policy:\n",
      "\n",
      "      \"I have read the late policy for CS6424.\"\n",
      "    \n",
      "Please type 'yes' to agree and continue>yes\n",
      "\n",
      "\n",
      "Honor Pledge:\n",
      "\n",
      "      \"I have read the Collaboration and Academic Honesty policy for CS6424.\n",
      "      I certify that I have or will use outside references only in accordance with\n",
      "      this policy, that I have or will cite any such references via code comments,\n",
      "      and that I have not or will not copy any portion of my submission from another\n",
      "      past or current student.\"\n",
      "\n",
      "    \n",
      "Please type 'yes' to agree and continue>yes\n",
      "\n",
      "\n",
      "Converted Q2.ipynb to submission/submission.py\n"
     ]
    }
   ],
   "source": [
    "%run helpers/notebook2script submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
